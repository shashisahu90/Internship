{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb0902a",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ae257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3df0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1240e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c25ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0eae2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554176c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b8c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb73a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21556d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business &amp; Data Analyst- Assistant Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>State Street</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Infometry</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Qualitest India Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr Clinical Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>LabCorp</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manager / Senior Manager - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Analyst- Immediate Joining</td>\n",
       "      <td>Bangalore/Bengaluru(Cox Town)</td>\n",
       "      <td>ADVISETREE CONSULTING PRIVATE LIMITED</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>milestone internet marketing pvt ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    job_title  \\\n",
       "0  Business & Data Analyst- Assistant Manager   \n",
       "1                   Sr. Business Data Analyst   \n",
       "2                         Senior Data Analyst   \n",
       "3                    Sr Clinical Data Analyst   \n",
       "4     Manager / Senior Manager - Data Analyst   \n",
       "5             DATA Analyst- Immediate Joining   \n",
       "6                                Data Analyst   \n",
       "7                                Data Analyst   \n",
       "8                         Senior Data Analyst   \n",
       "9                            Sr. Data Analyst   \n",
       "\n",
       "                                        job_location  \\\n",
       "0        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "5                      Bangalore/Bengaluru(Cox Town)   \n",
       "6                     Bangalore/Bengaluru, Ahmedabad   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8               Bangalore/Bengaluru(Old Madras Road)   \n",
       "9                          Bangalore/Bengaluru, Pune   \n",
       "\n",
       "                              company_name experience_required  \n",
       "0                             State Street             1-3 Yrs  \n",
       "1                                Infometry             4-6 Yrs  \n",
       "2          Qualitest India Private Limited             5-8 Yrs  \n",
       "3                                  LabCorp             2-5 Yrs  \n",
       "4                Huquo Consulting Pvt. Ltd             2-7 Yrs  \n",
       "5    ADVISETREE CONSULTING PRIVATE LIMITED             3-5 Yrs  \n",
       "6     milestone internet marketing pvt ltd             2-7 Yrs  \n",
       "7                                    Bayer             2-5 Yrs  \n",
       "8                                 KrazyBee             3-6 Yrs  \n",
       "9  Global Indian School Education Services            6-11 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame from above data:\n",
    "df=pd.DataFrame({})\n",
    "df['job_title']=job_title\n",
    "df['job_location']=job_location\n",
    "df['company_name']=company_name\n",
    "df['experience_required']=experience_required\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b7ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83a27556",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67887c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46356cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63459dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c82bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b57a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "331e2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a09e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51ee4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Manager - EmTech - Machine Learning - P&amp;T</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Lead_Tata Consultancy Services(...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                  Lead ML Scientist   \n",
       "1   Senior Manager - EmTech - Machine Learning - P&T   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "4  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "5  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "6                      Tcs Hiring For Data Scientist   \n",
       "7  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "8  Data Scientist Lead_Tata Consultancy Services(...   \n",
       "9                   Assistant Manager - Data Science   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                        Bangalore/Bengaluru, Mumbai   \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "4  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "5  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "6   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "7  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "8  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "9                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "\n",
       "                                  company_name  \n",
       "0                            Fractal Analytics  \n",
       "1                                          PwC  \n",
       "2                                    Accenture  \n",
       "3              TATA CONSULTANCY SERVICES (TCS)  \n",
       "4                                        Wipro  \n",
       "5  NTT DATA Business Solutions Private Limited  \n",
       "6              TATA CONSULTANCY SERVICES (TCS)  \n",
       "7                                        Wipro  \n",
       "8              TATA CONSULTANCY SERVICES (TCS)  \n",
       "9                                   CitiusTech  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame from above data:\n",
    "df=pd.DataFrame({})\n",
    "df['job_title']=job_title\n",
    "df['job_location']=job_location\n",
    "df['company_name']=company_name\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0008f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdf28684",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "736af492",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e630ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2cf37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18a340e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "486e63be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/p\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a10e8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/p\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9235d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "salary_range=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45d3de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "# Scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//div[@class=\"mt-7 companyInfo subheading lh16\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "    \n",
    "# scraping salary from the given page\n",
    "salary_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "for i in salary_tags[0:10]:\n",
    "    salary=i.text\n",
    "    salary_range.append(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f1ada1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required),len(salary_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "996eb931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>salary_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Chenn...</td>\n",
       "      <td>Wipro\\n3.9\\n(26533 Reviews)</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL\\n3.8\\n(951 Reviews)</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group\\n4.1\\n(117 Reviews)</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum\\n4.1\\n(1951 Reviews)</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chat-bot Developer / Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru\\n(WFH d...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>5,00,000 - 12,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra\\n3.9\\n(900 Reviews)</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>5,00,000 - 8,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>5,00,000 - 12,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES\\n4.2\\n(10 Reviews)</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "1                   Data Scientist - Noida/Bangalore   \n",
       "2                    DigitalBCG GAMMA Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4              Data Scientist - Predictive Analytics   \n",
       "5                Chat-bot Developer / Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                Data Scientist / Chat-bot Developer   \n",
       "8                  Data Scientist - Engine Algorithm   \n",
       "9         Data Scientist For Healthcare Product team   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  New Delhi, Hyderabad/Secunderabad, Pune, Chenn...   \n",
       "1                         Noida, Bangalore/Bengaluru   \n",
       "2                     New Delhi, Bangalore/Bengaluru   \n",
       "3                                   Gurgaon/Gurugram   \n",
       "4  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...   \n",
       "5  Mumbai, New Delhi, Bangalore/Bengaluru\\n(WFH d...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "8  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "9          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "\n",
       "                                  company_name experience_required  \\\n",
       "0                  Wipro\\n3.9\\n(26533 Reviews)            5-10 Yrs   \n",
       "1                      EXL\\n3.8\\n(951 Reviews)            5-10 Yrs   \n",
       "2  Boston Consulting Group\\n4.1\\n(117 Reviews)             2-5 Yrs   \n",
       "3                   Optum\\n4.1\\n(1951 Reviews)             2-7 Yrs   \n",
       "4                                 Confidential             1-6 Yrs   \n",
       "5                                 Big Seo Buzz             2-7 Yrs   \n",
       "6           Feedback Infra\\n3.9\\n(900 Reviews)             2-4 Yrs   \n",
       "7                                 Big Seo Buzz             3-7 Yrs   \n",
       "8                                 Primo Hiring             1-3 Yrs   \n",
       "9  SECUREKLOUD TECHNOLOGIES\\n4.2\\n(10 Reviews)             2-7 Yrs   \n",
       "\n",
       "               salary_range  \n",
       "0             Not disclosed  \n",
       "1             Not disclosed  \n",
       "2             Not disclosed  \n",
       "3             Not disclosed  \n",
       "4             Not disclosed  \n",
       "5  5,00,000 - 12,00,000 PA.  \n",
       "6   5,00,000 - 8,00,000 PA.  \n",
       "7  5,00,000 - 12,00,000 PA.  \n",
       "8             Not disclosed  \n",
       "9             Not disclosed  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame from above data:\n",
    "df=pd.DataFrame({})\n",
    "df['job_title']=job_title\n",
    "df['job_location']=job_location\n",
    "df['company_name']=company_name\n",
    "df['experience_required']=experience_required\n",
    "df['salary_range']=salary_range\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51bb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9176cf7d",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then \n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "954540cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24f739fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cc99f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b475b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the search button\n",
    "search=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30341ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "brand = []\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "descriptn = []\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.appendend(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "price = []\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]//span')\n",
    "discount = []\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad514b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the next button for page 2\n",
    "search_2 = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "search_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72e0b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.appendend(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0bc1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the next button for page 3\n",
    "search_2 = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "search_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f63d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 120 120 120 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglasses Brand</th>\n",
       "      <th>Sunglasses Description</th>\n",
       "      <th>Sunglasses Price</th>\n",
       "      <th>Sunglasses Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹749</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹298</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (47)</td>\n",
       "      <td>₹4,000</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Night Vision, Riding Glasses Rectangular Sungl...</td>\n",
       "      <td>₹255</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Mi</td>\n",
       "      <td>Polarized Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>24% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Gradient Butterfly Sunglasses (52)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sunglasses Brand                             Sunglasses Description  \\\n",
       "0     VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...   \n",
       "1     VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "2          Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3         Elligator                UV Protection Round Sunglasses (54)   \n",
       "4         New Specs   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "..              ...                                                ...   \n",
       "95      john jacobs           UV Protection Clubmaster Sunglasses (47)   \n",
       "96           GANSTA  Night Vision, Riding Glasses Rectangular Sungl...   \n",
       "97   ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...   \n",
       "98               Mi          Polarized Wayfarer Sunglasses (Free Size)   \n",
       "99        ROYAL SON  UV Protection, Gradient Butterfly Sunglasses (52)   \n",
       "\n",
       "   Sunglasses Price Sunglasses Discount  \n",
       "0              ₹749             70% off  \n",
       "1              ₹949             52% off  \n",
       "2              ₹799             20% off  \n",
       "3              ₹298             88% off  \n",
       "4              ₹264             89% off  \n",
       "..              ...                 ...  \n",
       "95           ₹4,000             33% off  \n",
       "96             ₹255             80% off  \n",
       "97             ₹349             82% off  \n",
       "98             ₹759             24% off  \n",
       "99             ₹664             66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.append(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)\n",
    "    \n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(brand), len(descriptn), len(price), len(discount))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Sunglasses Brand']=brand[:100]\n",
    "df['Sunglasses Description']=descriptn[:100]\n",
    "df['Sunglasses Price']=price[:100]\n",
    "df['Sunglasses Discount']=discount[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e269e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19ca270f",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button.\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c182d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05d13a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7a28a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys(\"iphone 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6256f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the search button\n",
    "search=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27678431",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e65814a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements(By.XPATH,'//nav[@class=\"yFHi8N\"]//a')\n",
    "\n",
    "prod_urls=[]\n",
    "for i in url[:11]:\n",
    "    prod_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aff313e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 107 110 110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iPhone Rating</th>\n",
       "      <th>iPhone Review Summary</th>\n",
       "      <th>iPhone Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I bought iPhone 11 On March 2021, And I am Wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Just go for it. This phone is really amazing. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Don’t expect much from front camera… especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone. And I truly don’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Absolutely powerful gadget. Loved it’s look! S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iPhone Rating  iPhone Review Summary  \\\n",
       "0              5         Simply awesome   \n",
       "1              5       Perfect product!   \n",
       "2              5    Best in the market!   \n",
       "3              5     Highly recommended   \n",
       "4              5      Worth every penny   \n",
       "..           ...                    ...   \n",
       "95             5               Terrific   \n",
       "96             5              Excellent   \n",
       "97             5    Best in the market!   \n",
       "98             5                 Super!   \n",
       "99             5  Mind-blowing purchase   \n",
       "\n",
       "                                   iPhone Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  I bought iPhone 11 On March 2021, And I am Wri...  \n",
       "96  Just go for it. This phone is really amazing. ...  \n",
       "97  Don’t expect much from front camera… especiall...  \n",
       "98  This is my first ever iPhone. And I truly don’...  \n",
       "99  Absolutely powerful gadget. Loved it’s look! S...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the ratings for the iPhone\n",
    "phone_rating = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_rating = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for j in prod_rating:\n",
    "            phone_rating.append(j.text)\n",
    "    except:\n",
    "        phone_rating.append(\"---\")\n",
    "\n",
    "# extract all the review summary for the iPhone\n",
    "review_summary = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_summaries = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "        for j in prod_summaries:\n",
    "            review_summary.append(j.text)\n",
    "    except:\n",
    "        review_summary.append(\"---\")\n",
    "\n",
    "# extract all the complete descriptive review for the iPhone\n",
    "full_review = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_reviews = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "        for j in prod_reviews:\n",
    "            full_review.append(j.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        full_review.append(\"---\")\n",
    "\n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(phone_rating), len(review_summary), len(full_review))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['iPhone Rating']=phone_rating[:100]\n",
    "df['iPhone Review Summary']=review_summary[:100]\n",
    "df['iPhone Full Review']=full_review[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc153727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccacc464",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6acc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65737d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc43d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the log-in page window\n",
    "close=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d76a9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter \"sneakers\" in \"search for products\" field\n",
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sneakers')\n",
    "\n",
    "#click the Search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6a7f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RESNAPSHOEZONE</td>\n",
       "      <td>Mesh | Ultralightweight | Comfortable | Breath...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RESNAPSHOEZONE</td>\n",
       "      <td>Puma Smash Wns v2 L Sneakers For Women</td>\n",
       "      <td>₹499</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹374</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,542</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹544</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Shoes For Women's/Ladies/Female/Girls Running ...</td>\n",
       "      <td>₹1,578</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DUNKASTON</td>\n",
       "      <td>Black Gym/Walking/Running Sports Sneakers For Men</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Vellinto</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹499</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Canvas Sneakers For Men</td>\n",
       "      <td>₹3,354</td>\n",
       "      <td>39% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FAUSTO</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹1,274</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description   Price  \\\n",
       "0   RESNAPSHOEZONE  Mesh | Ultralightweight | Comfortable | Breath...    ₹499   \n",
       "1   RESNAPSHOEZONE             Puma Smash Wns v2 L Sneakers For Women    ₹499   \n",
       "2             aadi  Super Stylish & Trendy Combo Pack of 02 Pairs ...    ₹374   \n",
       "3             PUMA                                   Sneakers For Men  ₹1,542   \n",
       "4           Chevit                                 Sneakers For Women    ₹544   \n",
       "..             ...                                                ...     ...   \n",
       "95     bacca bucci  Shoes For Women's/Ladies/Female/Girls Running ...  ₹1,578   \n",
       "96       DUNKASTON  Black Gym/Walking/Running Sports Sneakers For Men    ₹699   \n",
       "97        Vellinto                                 Sneakers For Women    ₹499   \n",
       "98            PUMA                            Canvas Sneakers For Men  ₹3,354   \n",
       "99          FAUSTO                                 Sneakers For Women  ₹1,274   \n",
       "\n",
       "   Discount  \n",
       "0   60% off  \n",
       "1   60% off  \n",
       "2   81% off  \n",
       "3   55% off  \n",
       "4   71% off  \n",
       "..      ...  \n",
       "95  54% off  \n",
       "96  65% off  \n",
       "97  61% off  \n",
       "98  39% off  \n",
       "99  57% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#introducing list for brand, product description, price & discount\n",
    "brand=[]\n",
    "prod1=[]\n",
    "prod2=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "# for scrapping data from different pages to get first 100 reviews, defining Start & End of the page\n",
    "for page in range(0,3):\n",
    "    \n",
    "# Scrapping brand list from different pages \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "        brand.append(i.text)\n",
    "        \n",
    "# Scrapping product description from different pages \n",
    "    for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "        prod1.append(j.text)\n",
    "        \n",
    "    for c in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "        prod2.append(c.text)\n",
    "    prod=prod1+prod2\n",
    "    \n",
    "# Scrapping price from different pages \n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(k.text)\n",
    "        \n",
    "# Scrapping discount from different pages \n",
    "    for l in driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]'):\n",
    "        discount.append(l.text)\n",
    "        \n",
    "#scraping the required data from different pages\n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "# converting scrapped data for first 100 reviews into DataFrame\n",
    "Sneaker_data=pd.DataFrame({'Brand':brand,'Product Description':prod,'Price':price,'Discount':discount})\n",
    "Sneaker_data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bcc257",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d44cd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8bb75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85c1d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the color filter for \"Black\"\n",
    "color_filter = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b05d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the second price filter \n",
    "price_filter = driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22bf0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements(By.XPATH,'//li[@class=\"pagination-number\"]//a')\n",
    "\n",
    "# extract all the shoe links from the above search result\n",
    "shoe_urls=[]\n",
    "for i in url[:5]:\n",
    "    shoe_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402af93",
   "metadata": {},
   "source": [
    "Further steps can't be done because \"Inspect\" icon is not displayed on right-click. As per Mentor's direction, this question need not to be solved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7440329b",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "afe07e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d90ab497",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://www.amazon.in/ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "166a15e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.XPATH,'//input[@id=\"twotabsearchtextbox\"]')\n",
    "product.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be6e7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'//input[@id=\"nav-search-submit-button\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9a1d98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the CPU filter for \"Intel Core i7\"\n",
    "CPU = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[4]/li[13]/span/a/span\")\n",
    "CPU.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3b7bf6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Laptop Rating</th>\n",
       "      <th>Laptop Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17\"(43cm)Ul...</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>92,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>54,840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>82,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) DELL Alienware x14 Gaming Laptop, In...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>1,69,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Gaming3 Laptop Intel i7 10th Ge...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>76,588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title       Laptop Rating  \\\n",
       "0  LG Gram Intel Evo 11th Gen Core i7 17\"(43cm)Ul...  4.7 out of 5 stars   \n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...  4.5 out of 5 stars   \n",
       "2  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...  3.9 out of 5 stars   \n",
       "3  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.6 out of 5 stars   \n",
       "4  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.2 out of 5 stars   \n",
       "5  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  5.0 out of 5 stars   \n",
       "6  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...  4.1 out of 5 stars   \n",
       "7  (Renewed) DELL Alienware x14 Gaming Laptop, In...  4.0 out of 5 stars   \n",
       "8  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...  3.8 out of 5 stars   \n",
       "9  Lenovo IdeaPad Gaming3 Laptop Intel i7 10th Ge...  3.6 out of 5 stars   \n",
       "\n",
       "  Laptop Price  \n",
       "0       92,999  \n",
       "1       84,990  \n",
       "2       62,990  \n",
       "3       54,840  \n",
       "4       89,990  \n",
       "5       81,990  \n",
       "6       82,400  \n",
       "7     1,69,992  \n",
       "8       87,990  \n",
       "9       76,588  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to extract laptop title\n",
    "ltitle=[]\n",
    "lappy_title = driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in lappy_title[:10]:\n",
    "    ltitle.append(i.text)\n",
    "\n",
    "# code to extract laptop rating\n",
    "lrating=[]\n",
    "lappy_rating = driver.find_elements(By.CLASS_NAME,\"a-icon-alt\")\n",
    "for i in lappy_rating[:10]:\n",
    "    lrating.append(i.get_attribute('textContent'))\n",
    "\n",
    "# code to extract laptop price\n",
    "lprice=[]\n",
    "lappy_price = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in lappy_price[:10]:\n",
    "    lprice.append(i.text)\n",
    "    \n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(ltitle), len(lrating), len(lprice))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Laptop Title']=ltitle\n",
    "df['Laptop Rating']=lrating\n",
    "df['Laptop Price']=lprice\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b85a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6ade501",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida \n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c376954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbabc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d12c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on \"Job\" options\n",
    "jobs=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[5]/a')\n",
    "jobs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adc42f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering \"Data Scientist\" in \"Skill, Designation, Companies\" field\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search.send_keys('Data Scientist')\n",
    "\n",
    "# clicking the Search button\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56c7b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on location icon\n",
    "location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]')\n",
    "location.click()\n",
    "\n",
    "# entering \"Noida\" for location search\n",
    "place=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "place.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c52539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the Search button\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa968f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of Days ago when job was posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>28d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SOPRA STERIA INDIA LIMITED</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company Name  \\\n",
       "0                         CBRE South Asia Pvt Ltd   \n",
       "1                   GENPACT India Private Limited   \n",
       "2                                         Genpact   \n",
       "3        Ericsson India Global Services Pvt. Ltd.   \n",
       "4                   GENPACT India Private Limited   \n",
       "5  Optum Global Solutions (India) Private Limited   \n",
       "6  Optum Global Solutions (India) Private Limited   \n",
       "7        Ericsson India Global Services Pvt. Ltd.   \n",
       "8                      SOPRA STERIA INDIA LIMITED   \n",
       "9                EXL Services.com ( I ) Pvt. Ltd.   \n",
       "\n",
       "  No. of Days ago when job was posted Rating  \n",
       "0                              8d ago    4.3  \n",
       "1                              1d ago    4.0  \n",
       "2                              3d ago    4.0  \n",
       "3                             18d ago    4.3  \n",
       "4                             11d ago    4.0  \n",
       "5                             15d ago    4.1  \n",
       "6                             16d ago    4.1  \n",
       "7                             28d ago    4.3  \n",
       "8                             17d ago    4.2  \n",
       "9                             17d ago    3.9  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping company name from the webpage\n",
    "company=[]\n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]'): #scrapping company name from page\n",
    "    company.append(i.text)\n",
    "\n",
    "# Scrapping No. of days ago when job was posted from the webpage\n",
    "day=[]\n",
    "for j in driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]'):\n",
    "    day.append(j.text)\n",
    "del day[1:20:2] \n",
    "    \n",
    "# Scrapping Rating of the Company from the webpage\n",
    "rating=[]\n",
    "for k in driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]'):\n",
    "    rating.append(k.text)\n",
    "\n",
    "# converting scrapped data into DataFrame\n",
    "Jobs=pd.DataFrame({'Company Name':company, 'No. of Days ago when job was posted':day, 'Rating':rating})\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c328f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac6ae327",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. \n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edeadb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07d89196",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2475bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select salary option\n",
    "salary=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[3]/a')\n",
    "salary.click()\n",
    "\n",
    "# select first option from drop down menu\n",
    "browser=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[3]/div/ul/li[1]/div/div[2]/p')\n",
    "browser.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7bc283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter 'Data Scientist' in Search job profile\n",
    "job_profile=driver.find_element(By.XPATH,'//input[@class=\"tt-input\"]')\n",
    "job_profile.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "770dbd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select first option from drop down menu\n",
    "select=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28000233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 31.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 48 salaries</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 109 salaries</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 65 salaries</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 91 salaries</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ford Motor</td>\n",
       "      <td>based on 21 salaries</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Name    Total Salary Record Average Salary  \\\n",
       "0                     Walmart   based on 22 salaries        ₹ 31.7L   \n",
       "1                    Ab Inbev   based on 53 salaries        ₹ 19.7L   \n",
       "2                       Optum   based on 48 salaries        ₹ 16.5L   \n",
       "3                          ZS   based on 33 salaries        ₹ 15.7L   \n",
       "4           Fractal Analytics  based on 109 salaries        ₹ 15.2L   \n",
       "5             Tiger Analytics   based on 65 salaries        ₹ 14.7L   \n",
       "6  Legato Health Technologies   based on 11 salaries        ₹ 14.5L   \n",
       "7                    Tredence   based on 12 salaries        ₹ 14.1L   \n",
       "8                UnitedHealth   based on 91 salaries        ₹ 13.6L   \n",
       "9                  Ford Motor   based on 21 salaries        ₹ 13.5L   \n",
       "\n",
       "  Minimum Salary Maximum Salary  Experience Required  \n",
       "0        ₹ 25.0L        ₹ 45.0L  3-4 yrs experience   \n",
       "1        ₹ 15.0L        ₹ 25.5L  2-4 yrs experience   \n",
       "2        ₹ 11.0L        ₹ 22.6L  2-4 yrs experience   \n",
       "3        ₹ 11.0L        ₹ 22.0L  1-2 yrs experience   \n",
       "4         ₹ 9.0L        ₹ 23.0L  2-4 yrs experience   \n",
       "5         ₹ 9.0L        ₹ 20.0L  2-4 yrs experience   \n",
       "6        ₹ 11.0L        ₹ 20.0L    4 yrs experience   \n",
       "7         ₹ 8.8L        ₹ 17.5L    3 yrs experience   \n",
       "8         ₹ 8.0L        ₹ 20.5L  2-4 yrs experience   \n",
       "9        ₹ 10.0L        ₹ 18.0L  3-4 yrs experience   "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape company name from the webpage\n",
    "comp=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]/a'):\n",
    "    comp.append(i.text.split(\"\\n\"))\n",
    "    \n",
    "# merge sub lists into a single list and delete even place items to get required data\n",
    "company=sum(comp,[])\n",
    "del company[1:20:2]\n",
    "\n",
    "# Scrape total salary record from the webpage\n",
    "sal_record=[]\n",
    "for a in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]/span'):\n",
    "    sal_record.append(a.text.replace('(','').replace(')',''))\n",
    "\n",
    "# Scrape Average salary from the webpage\n",
    "avg_sal=[]\n",
    "for b in driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]'): \n",
    "    avg_sal.append(b.text)\n",
    "\n",
    "# Scrape Minimum Salary & Maximum Salary from the webpage\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "for c in driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]'): \n",
    "    min_sal.append(c.text)\n",
    "    max_sal.append(c.text)\n",
    "del min_sal[1:20:2]\n",
    "del max_sal[0:20:2]\n",
    "\n",
    "# Scrape Experience required data from the webpage\n",
    "exp=[]\n",
    "for d in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]'): \n",
    "    exp.append(d.text.split('('))\n",
    "    \n",
    "# merge sub lists into a single list and delete even place items to get required data   \n",
    "req_exp=sum(exp,[]) \n",
    "del req_exp[1:20:2]\n",
    "\n",
    "# convert scrapped data into DataFrame\n",
    "df=pd.DataFrame({'Company Name':company,'Total Salary Record':sal_record,'Average Salary':avg_sal,'Minimum Salary':min_sal,'Maximum Salary':max_sal,'Experience Required':req_exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09b826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7243dc34",
   "metadata": {},
   "source": [
    "Assignment done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744ddb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
